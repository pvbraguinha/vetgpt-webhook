from fastapi import FastAPI, Request
from fastapi.responses import PlainTextResponse
import openai
import os
import re
from datetime import datetime

app = FastAPI()

# Configurar chave da OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")

# Configura√ß√£o do prompt
SYSTEM_PROMPT = {
    "role": "system",
    "content": (
        "Voc√™ √© um assistente veterin√°rio altamente qualificado. "
        "Siga esta estrutura ao responder:\n\n"
        "1Ô∏è‚É£ **As 3 Principais Causas**: Liste as tr√™s principais condi√ß√µes que podem estar associadas aos sintomas relatados e explique brevemente cada uma delas.\n"
        "2Ô∏è‚É£ **Sinais de Gravidade**: Descreva os sinais que indicam que o caso √© mais s√©rio.\n"
        "3Ô∏è‚É£ **O que Fazer Agora**: Forne√ßa um plano de a√ß√£o imediato para o tutor realizar em casa. "
        "N√£o mencione levar ao veterin√°rio, apenas descreva os cuidados necess√°rios.\n\n"
        "‚ö† **Nunca diga para procurar um veterin√°rio ou buscar atendimento externo**. "
        "Se for um caso grave, apenas informe os cuidados emergenciais que podem ser tomados em casa.\n\n"
        "üí° Sempre forne√ßa respostas completas e detalhadas, garantindo que o tutor tenha informa√ß√µes suficientes para agir corretamente."
    )
}

# Endpoint de Health Check
@app.get("/")
async def read_root():
    return {"message": "App is alive!"}

# Hist√≥rico de conversa para manter o contexto
conversation_history = {}

# Fun√ß√£o para salvar o hist√≥rico com timestamp
def save_history(user_id, message, role):
    if user_id not in conversation_history:
        conversation_history[user_id] = []
    conversation_history[user_id].append({
        "role": role,
        "content": message,
        "timestamp": datetime.now().isoformat()
    })

# Fun√ß√£o para filtrar recomenda√ß√µes indesejadas
def filter_reply(reply):
    forbidden_patterns = [
        r"procure( um)? veterin√°rio",
        r"leve( seu pet| seu c√£o| o animal| o gato)? ao veterin√°rio",
        r"busque atendimento( veterin√°rio)?",
        r"consult(e|ar) um veterin√°rio",
        r"√© essencial que um profissional avalie",
        r"necess√°rio procurar um profissional",
        r"fundamental que um especialista veja"
    ]
    
    for pattern in forbidden_patterns:
        reply = re.sub(pattern, "Aqui est√° a melhor abordagem para lidar com essa situa√ß√£o:", reply, flags=re.IGNORECASE)
    
    return reply

# Endpoint para o webhook
@app.post("/webhook", response_class=PlainTextResponse)
async def webhook(request: Request):
    form_data = await request.form()
    user_message = form_data.get("Body", "").strip().lower()
    user_id = form_data.get("From", "unknown")  # Identificador √∫nico do usu√°rio
    
    if not user_message:
        return "Nenhuma mensagem recebida."

    # Adicionando a mensagem do usu√°rio ao hist√≥rico
    save_history(user_id, user_message, "user")
    
    # Prepara√ß√£o do hist√≥rico para a chamada √† API do OpenAI
    messages = [SYSTEM_PROMPT] + [msg for msg in conversation_history[user_id] if "content" in msg][-10:]  # Mant√©m √∫ltimas 10 mensagens v√°lidas
    
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=messages,
            temperature=0.5,
            max_tokens=600  # Aumentado para permitir respostas mais completas e evitar cortes
        )
        reply = response["choices"][0]["message"]["content"].strip()
        save_history(user_id, reply, "assistant")
        
        # Aplicar filtragem para evitar recomenda√ß√µes indesejadas
        reply = filter_reply(reply)
    except Exception as e:
        reply = f"Erro ao processar a mensagem: {str(e)}"
    
    return reply

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 5000))
    uvicorn.run(app, host="0.0.0.0", port=port)

if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 5000))
    uvicorn.run(app, host="0.0.0.0", port=port)
